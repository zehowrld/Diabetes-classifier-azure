{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tune hyperparameters with a sweep job\n",
        "\n",
        "There are many machine learning algorithms that require hyperparameters (parameter values that influence training, but can't be determined from the training data itself). For example, when training a logistic regression model, you can use a regularization rate hyperparameter to counteract bias in the model; or when training a convolutional neural network, you can use hyperparameters like learning rate and batch size to control how weights are adjusted and how many data items are processed in a mini-batch respectively. The choice of hyperparameter values can significantly affect the performance of a trained model, or the time taken to train it; and often you need to try multiple combinations to find the optimal solution. \n",
        "\n",
        "## Before you start\n",
        "\n",
        "You'll need the latest version of the  **azureml-ai-ml** package to run the code in this notebook. Run the cell below to verify that it is installed.\n",
        "\n",
        "> **Note**:\n",
        "> If the **azure-ai-ml** package is not installed, run `pip install azure-ai-ml` to install it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667591781367
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "pip show azure-ai-ml"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "With the required SDK packages installed, now you're ready to connect to your workspace.\n",
        "\n",
        "To connect to a workspace, we need identifier parameters - a subscription ID, resource group name, and workspace name. Since you're working with a compute instance, managed by Azure Machine Learning, you can use the default values to connect to the workspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667591793668
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667591797746
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Get a handle to workspace\n",
        "ml_client = MLClient.from_config(credential=credential)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the training script\n",
        "Hyperparameter tuning is ideal when you want to train a machine learning models but vary the input parameters. You'll need to create a training script that expects an input parameter representing one of the algorithm's hyperparameters.\n",
        "\n",
        "Run the following cells to create the **src** folder and the training script.\n",
        "\n",
        "Note that the training script expects two input parameters:\n",
        "\n",
        "- `--training_data` which expects a string. You'll specify the path to a registered data asset as the input training data.\n",
        "- `--reg_rate` which expects a number, but has a default value of `0.01`. You'll use this input parameter for hyperparameter tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667591853637
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# create a folder for the script files\n",
        "script_folder = 'src'\n",
        "os.makedirs(script_folder, exist_ok=True)\n",
        "print(script_folder, 'folder created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%writefile $script_folder/train.py\n",
        "# import libraries\n",
        "import mlflow\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def main(args):\n",
        "    # read data\n",
        "    df = get_data(args.training_data)\n",
        "\n",
        "    # split data\n",
        "    X_train, X_test, y_train, y_test = split_data(df)\n",
        "\n",
        "    # train model\n",
        "    model = train_model(args.reg_rate, X_train, X_test, y_train, y_test)\n",
        "\n",
        "    # evaluate model\n",
        "    eval_model(model, X_test, y_test)\n",
        "\n",
        "# function that reads the data\n",
        "def get_data(path):\n",
        "    print(\"Reading data...\")\n",
        "    df = pd.read_csv(path)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# function that splits the data\n",
        "def split_data(df):\n",
        "    print(\"Splitting data...\")\n",
        "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
        "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# function that trains the model\n",
        "def train_model(reg_rate, X_train, X_test, y_train, y_test):\n",
        "    mlflow.log_param(\"Regularization rate\", reg_rate)\n",
        "    print(\"Training model...\")\n",
        "    model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "    return model\n",
        "\n",
        "# function that evaluates the model\n",
        "def eval_model(model, X_test, y_test):\n",
        "    # calculate accuracy\n",
        "    y_hat = model.predict(X_test)\n",
        "    acc = np.average(y_hat == y_test)\n",
        "    print('Accuracy:', acc)\n",
        "    mlflow.log_metric(\"training_accuracy_score\", acc)\n",
        "\n",
        "    # calculate AUC\n",
        "    y_scores = model.predict_proba(X_test)\n",
        "    auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "    print('AUC: ' + str(auc))\n",
        "    mlflow.log_metric(\"AUC\", auc)\n",
        "\n",
        "    # plot ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
        "    fig = plt.figure(figsize=(6, 4))\n",
        "    # Plot the diagonal 50% line\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    # Plot the FPR and TPR achieved by our model\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.savefig(\"ROC-Curve.png\")\n",
        "    mlflow.log_artifact(\"ROC-Curve.png\")    \n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--training_data\", dest='training_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--reg_rate\", dest='reg_rate',\n",
        "                        type=float, default=0.01)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure and run a command job\n",
        "\n",
        "Run the cell below to train a classification model to predict diabetes. The model is trained by running the **train\\.py** script that can be found in the **src** folder. It uses the registered `diabetes-data` data asset as the training data. \n",
        "\n",
        "- `code`: specifies the folder that includes the script to run.\n",
        "- `command`: specifies what to run exactly.\n",
        "- `environment`: specifies the necessary packages to be installed on the compute before running the command.\n",
        "- `compute`: specifies the compute to use to run the command.\n",
        "- `display_name`: the name of the individual job.\n",
        "- `experiment_name`: the name of the experiment the job belongs to.\n",
        "\n",
        "Note that the command job only runs the training script once, with a regularization rate of `0.1`. Before you run a sweep job to tune hyperparameters, it's a best practice to test whether your script works as expected with a command job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667592538771
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import command, Input\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "# configure job\n",
        "\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python train.py --training_data ${{inputs.diabetes_data}} --reg_rate ${{inputs.reg_rate}}\",\n",
        "    inputs={\n",
        "        \"diabetes_data\": Input(\n",
        "            type=AssetTypes.URI_FILE, \n",
        "            path=\"azureml:diabetes-data:1\"\n",
        "            ),\n",
        "        \"reg_rate\": 0.01,\n",
        "    },\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"aml-cluster\",\n",
        "    display_name=\"diabetes-train-mlflow\",\n",
        "    experiment_name=\"diabetes-training\", \n",
        "    tags={\"model_type\": \"LogisticRegression\"}\n",
        "    )\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Define the search space\n",
        "\n",
        "When your command job has completed successfully, you can configure and run a sweep job. \n",
        "\n",
        "First, you'll need to specify the search space for your hyperparameter. To train three models, each with a different regularization rate (`0.01`, `0.1`, or `1`), you can define the search space with a `Choice` hyperparameter. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667592546442
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.sweep import Choice\n",
        "\n",
        "command_job_for_sweep = job(\n",
        "    reg_rate=Choice(values=[0.01, 0.1, 1]),\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure and submit the sweep job\n",
        "\n",
        "You'll use the sweep function to do hyperparameter tuning on your training script. To configure a sweep job, you'll need to configure the following:\n",
        "\n",
        "- `compute`: Name of the compute target to execute the job on.\n",
        "- `sampling_algorithm`: The hyperparameter sampling algorithm to use over the search space. Allowed values are `random`, `grid` and `bayesian`.\n",
        "- `primary_metric`: The name of the primary metric reported by each trial job. The metric must be logged in the user's training script using `mlflow.log_metric()` with the same corresponding metric name.\n",
        "- `goal`: The optimization goal of the `primary_metric`. The allowed values are `maximize` and `minimize`.\n",
        "- `limits`: Limits for the sweep job. For example, the maximum amount of trials or models you want to train.\n",
        "\n",
        "Note that the command job is used as the base for the sweep job. The configuration for the command job will be reused by the sweep job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667592681475
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# apply the sweep parameter to obtain the sweep_job\n",
        "sweep_job = command_job_for_sweep.sweep(\n",
        "    compute=\"aml-cluster\",\n",
        "    sampling_algorithm=\"grid\",\n",
        "    primary_metric=\"training_accuracy_score\",\n",
        "    goal=\"Maximize\",\n",
        ")\n",
        "\n",
        "# set the name of the sweep job experiment\n",
        "sweep_job.experiment_name=\"sweep-diabetes\"\n",
        "\n",
        "# define the limits for this sweep\n",
        "sweep_job.set_limits(max_total_trials=4, max_concurrent_trials=2, timeout=7200)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the following cell to submit the sweep job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667592716881
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "returned_sweep_job = ml_client.create_or_update(sweep_job)\n",
        "aml_url = returned_sweep_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When the job is completed, navigate to the job overview. The **Trials** tab will show all models that have been trained and how the `Accuracy` score differs for each regularization rate value you tried."
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
